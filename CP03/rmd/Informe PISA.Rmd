---
title: "Informe PISA"
author: "Beatriz Quevedo"
date: "`r Sys.Date()`"
output:
   prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción
El conjunto de datos a utilizar en este trabajo se ha construido utilizando la puntuación media en Ciencias por país del Programa para la Evaluación Internacional de Estudiantes (PISA) 2006, junto con el GNI per cápita (paridad del poder adquisitivo, dólares de 2005), el índice educativo, el índice de salud y el índice de desarrollo humano de la ONU (HDI).

Las variables clave son las siguientes:

* Overall Science Score (average score for 15 year olds)
* Interest in science
* Support for scientific inquiry
* Income Index
* Health Index
* Education Index
* Human Development Index (composed of the Income index, Health Index, and Education Index)

# Objetivo 

El obejtivo de este trabajo es modelizar la relación entre la puntuación media (OSS) y el resto de variables, utilizando modelos de splines y GAM aplicando la validación cruzada cuando sea necesario.

# Importación de Librerías

```{r Librerias, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom) # modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # estimar gam
library(skimr) # summary
library(reshape2) # melt
library(janitor)  # clean names
library(gam) # gam con splines
library(psych) # describe 
library(ggplot2)
library(magrittr) # Pipe operators
library(ISLR)
library(splines)
```


# Importación del DataFrame

```{r Read Data}
pisa <-  read.csv("../data/pisasci2006.csv")
```



# Tratamiento de las variables

### Renombre de columnas

Se renombran las columnbas de tal manera que las variables estén todas en minúscula.
```{r}
pisa %<>% clean_names()
colnames(pisa)
```

### Variables clave

Se seleccionan las variables clave del DataFrame.
```{r}
pisa %<>% select(overall, interest, support, income, health, edu, hdi)
```


### Identificación de filas duplicadas

No hay valores duplicados, por lo que no hace falta eliminar ninguna fila.
```{r}
nrow(pisa[duplicated(pisa), ])
```

### Identificación de valores nulos

Confirmamos que hay al menos un valor nulo en el DataFrame.
```{r}
any(is.na(pisa)) 
```

Hay un total de 44 valores (el 9,7% del DataFrame), por lo tanto al ser tantos valores nulos no se eliminarán para no perder información. Para que no interfieran con los análisis posteriores, estos valores serán cambiados por la media de cada columna.
```{r}
sum(is.na(pisa))
```

```{r}
for(i in 1:ncol(pisa)){
  pisa[is.na(pisa[,i]), i] <- mean(pisa[,i], na.rm = TRUE)
}
```

Y finalmente se comprueba que ya no hay valores nulos.
```{r}
sum(is.na(pisa))
```

# Relación gráfica de las variables con la variable objetivo

```{r}
par(mfrow=c(2,3))
plot(pisa$overall, pisa$interest) + 
plot(pisa$overall, pisa$support) + 
plot(pisa$overall, pisa$income) + 
plot(pisa$overall, pisa$health) + 
plot(pisa$overall, pisa$edu) +
plot(pisa$overall, pisa$hdi)
```

# Splines 

Se calculan los splines suavizados de cada variable para obtener los grados de libertad de cada uno, aplicando cross validation.
```{r, message=FALSE,warning=FALSE}

# interest = 4.75
spline_interest <- smooth.spline(x = pisa$interest, y = pisa$overall, cv = TRUE)
spline_interest$df

# support = 2
spline_support <- smooth.spline(x = pisa$support, y = pisa$overall, cv = TRUE)
spline_support$df

# income = 4.24
spline_income <- smooth.spline(x = pisa$income, y = pisa$overall, cv = TRUE)
spline_income$df

# health = 2
spline_health <- smooth.spline(x = pisa$health, y = pisa$overall, cv = TRUE)
spline_health$df

# edu = 2
spline_edu <- smooth.spline(x = pisa$edu, y = pisa$overall, cv = TRUE)
spline_edu$df

# hdi = 8.6
spline_hdi <- smooth.spline(x = pisa$hdi, y = pisa$overall, cv = TRUE)
spline_hdi$df

```

# GAM

Se crea un primer modelo GAM para predecir la puntuación media usando splines suavizados con los grados de libertad obtenidos y graficamos el comportamiento de las variables independientes.
```{r}
gamsplines <- gam(overall ~ s(interest, 4.75) + s(support, 2) + s(income, 4.24) + s(health, 2) + s(edu, 2) + s(hdi, 8.6), data = pisa)
```

Así, se observa que se comportan de manera más o menos lineal _health_ y _edu_.
```{r}
par(mfrow = c(3, 2))
plot(gamsplines, se = TRUE, col = 'orange', lwd = 1)
```

Se utilizará otro modelo GAM para predecir la puntuación media usando splines suavizados de las variables independientes, pero esta vez sin indicar sus grados de libertad. 
```{r}
gam <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
```

Graficamos el modelo por variables independientes, y se puede apreciar cómo la linealidad de _health_ y _edu_ ha empeorado.
```{r}
par(mfrow = c(3, 2))
plot(gam, se = TRUE, col = 'purple', lwd = 1)
```
Se crea un tercer modelo GAM pero con las variables que parecen ser más lineales.
```{r}
gamln <- gam(overall ~  s(health, 2) + s(edu, 2), data = pisa)
```

```{r}
par(mfrow = c(2, 1))
plot(gamln, se = TRUE, col = 'green', lwd = 1)
```

Se realiza un análisis de la varianza (ANOVA) para decidir entre _gam_, _gamsplines_ y _gamln_.
```{r}
anova(gamsplines, gam, gamln, test='F')
```
Parece que un modelo con _health_ y _edu_ es mucho mejor, al tener mucha significación, que modelos con todas las variables.

```{r}
summary(gamln)
```
